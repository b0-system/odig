<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Stream (aws-s3.Aws_s3__.S3.Make.Stream)</title><link rel="stylesheet" href="../../../../../_odoc-theme/odoc.css"/><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div class="content"><header><nav><a href="../index.html">Up</a> â€“ <a href="../../../../index.html">aws-s3</a> &#x00BB; <a href="../../../index.html">Aws_s3__</a> &#x00BB; <a href="../../index.html">S3</a> &#x00BB; <a href="../index.html">Make</a> &#x00BB; Stream</nav><h1>Module <code>Make.Stream</code></h1><p>Streaming functions. Streaming function seeks to limit the amount of used memory used when operating of large objects by operating on streams.</p></header><dl><dt class="spec value" id="val-put"><a href="#val-put" class="anchor"></a><code><span class="keyword">val</span> put : (?&#8288;content_type:string <span>&#45;&gt;</span> ?&#8288;content_encoding:string <span>&#45;&gt;</span> ?&#8288;acl:string <span>&#45;&gt;</span> ?&#8288;cache_control:string <span>&#45;&gt;</span> ?&#8288;expect:bool <span>&#45;&gt;</span> bucket:string <span>&#45;&gt;</span> key:string <span>&#45;&gt;</span> data:string <a href="../argument-1-Io/Pipe/index.html#type-reader">Io.Pipe.reader</a> <span>&#45;&gt;</span> chunk_size:int <span>&#45;&gt;</span> length:int <span>&#45;&gt;</span> unit <span>&#45;&gt;</span> <a href="../index.html#type-etag">etag</a> <a href="../index.html#type-result">result</a>) <a href="../index.html#type-command">command</a></code></dt><dd><p>Streaming version of put.</p><dl><dt>parameter length</dt><dd><p>Amount of data to copy</p></dd></dl><dl><dt>parameter chunk_size</dt><dd><p>The size of chunks send to s3. The system will have 2 x chunk_size byte in flight</p></dd></dl><dl><dt>parameter data</dt><dd><p>stream to be uploaded. Data will not be consumed after the result is determined. If using <code>expect</code>, then data may not have been consumed at all, but it is up to the caller to test if data has been consumed from the input data.</p><p>see <a href="../../../Aws_s3/S3/Make/index.html#val-put"><code>Aws_s3.S3.Make.put</code></a></p></dd></dl></dd></dl><dl><dt class="spec value" id="val-get"><a href="#val-get" class="anchor"></a><code><span class="keyword">val</span> get : (?&#8288;range:<a href="../index.html#type-range">range</a> <span>&#45;&gt;</span> bucket:string <span>&#45;&gt;</span> key:string <span>&#45;&gt;</span> data:string <a href="../argument-1-Io/Pipe/index.html#type-writer">Io.Pipe.writer</a> <span>&#45;&gt;</span> unit <span>&#45;&gt;</span> unit <a href="../index.html#type-result">result</a>) <a href="../index.html#type-command">command</a></code></dt><dd><p>Streaming version of get. The caller must supply a <code>data</code> sink to which retrieved data is streamed. The result will be determined after all data has been sent to the sink, and the data sink is closed.</p><p>Connections to s3 is closed once the result has been determined. The caller should ways examine the result of the function. If the result is <code>Ok ()</code>, then it is guaranteed that all data has been retrieved successfully and written to the data sink. In case of <code>Error _</code>, only parts of the data may have been written to the data sink.</p><p>The rationale for using a data sink rather than returning a pipe reader from which data can be consumed is that a reader does not allow simple relay of error states during the transfer.</p><p>For other parameters see <a href="../../../Aws_s3/S3/Make/index.html#val-get"><code>Aws_s3.S3.Make.get</code></a></p></dd></dl></div></body></html>