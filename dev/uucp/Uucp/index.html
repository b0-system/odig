<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Uucp (uucp.Uucp)</title><link rel="stylesheet" href="../../_odoc-theme/odoc.css"/><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div class="content"><header><nav><a href="../index.html">Up</a> – <a href="../index.html">uucp</a> &#x00BB; Uucp</nav><h1>Module <code>Uucp</code></h1><p>Unicode character properties.</p><p><code>Uucp</code> provides efficient access to a selection of character <a href="index.html#props"><span>properties</span></a> of the Unicode character database.</p><p>Consult a <a href="index.html#uminimal"><span>minimal Unicode introduction</span></a> and <a href="index.html#tips"><span>tips</span></a> for Unicode processing in OCaml. Individual modules have sample code related to the properties.</p><p><em>v11.0.0 — Unicode version 11.0.0 — <a href="http://erratique.ch/software/uucp">homepage</a></em></p><h4 id="references"><a href="#references" class="anchor"></a>References</h4><ul><li><a href="http://www.unicode.org/faq/">The Unicode FAQ.</a></li><li>The Unicode Consortium. <em><a href="http://www.unicode.org/versions/latest">The Unicode Standard</a></em>. (latest version)</li><li>Mark Davis, Ken Whistler. <em><a href="http://www.unicode.org/reports/tr44/">UAX #44 Unicode Character Database</a></em>. (latest version)</li></ul><nav class="toc"><ul><li><a href="#props">Properties</a></li><li><a href="#distrib_omit">Property module distribution and omissions</a></li><li><a href="#uminimal">Minimal Unicode introduction</a><ul><li><a href="#characters">Characters — if they exist</a></li><li><a href="#assignements">Interlude — what is assigned ?</a></li><li><a href="#serializing">Serializing integers — UTF-X</a></li><li><a href="#interlude-—-useful-scalar-values">Interlude — Useful scalar values</a></li><li><a href="#equivalence">Equivalence and normalization</a></li><li><a href="#collation">Collation — sorting in alphabetical order</a></li></ul></li><li><a href="#tips">Biased tips for OCaml programs and libraries</a><ul><li><a href="#uchartype">Unicode characters (scalar values) as <em></em> values.</a></li><li><a href="#utf_8_strings">Unicode text as UTF-8 encoded OCaml strings</a></li><li><a href="#utf_8_ascii">UTF-8 and ASCII</a></li><li><a href="#eqcmpnorm">Equate, compare and normalize UTF-8 encoded OCaml strings</a></li><li><a href="#alphasort">Sort strings alphabetically</a></li><li><a href="#boundaries">Find user-perceived character, word, sentence and line boundaries in Unicode text.</a></li><li><a href="#readline">Unicode readline</a></li><li><a href="#noranges">Range processing</a></li><li><a href="#transcode">Transcoding</a></li><li><a href="#ppcp">Pretty-printing code points in ASCII</a></li><li><a href="#ocamllibs">Writing OCaml libraries</a></li></ul></li></ul></nav></header><section><header><h2 id="props"><a href="#props" class="anchor"></a>Properties</h2><p>Consult information about the <a href="index.html#distrib_omit"><span>property distribution in modules and omissions</span></a>.</p></header><dl><dt class="spec value" id="val-unicode_version"><a href="#val-unicode_version" class="anchor"></a><code><span class="keyword">val</span> unicode_version : string</code></dt><dd><p><code>unicode_version</code> is the Unicode version supported by the library.</p></dd></dl><dl><dt class="spec module" id="module-Age"><a href="#module-Age" class="anchor"></a><code><span class="keyword">module</span> <a href="Age/index.html">Age</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Age property.</p></dd></dl><dl><dt class="spec module" id="module-Alpha"><a href="#module-Alpha" class="anchor"></a><code><span class="keyword">module</span> <a href="Alpha/index.html">Alpha</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Alphabetic property.</p></dd></dl><dl><dt class="spec module" id="module-Block"><a href="#module-Block" class="anchor"></a><code><span class="keyword">module</span> <a href="Block/index.html">Block</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Block property and block ranges.</p></dd></dl><dl><dt class="spec module" id="module-Break"><a href="#module-Break" class="anchor"></a><code><span class="keyword">module</span> <a href="Break/index.html">Break</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Break properties.</p></dd></dl><dl><dt class="spec module" id="module-Case"><a href="#module-Case" class="anchor"></a><code><span class="keyword">module</span> <a href="Case/index.html">Case</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Case properties, mappings and foldings.</p></dd></dl><dl><dt class="spec module" id="module-Cjk"><a href="#module-Cjk" class="anchor"></a><code><span class="keyword">module</span> <a href="Cjk/index.html">Cjk</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>CJK properties.</p></dd></dl><dl><dt class="spec module" id="module-Func"><a href="#module-Func" class="anchor"></a><code><span class="keyword">module</span> <a href="Func/index.html">Func</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Function and graphics properties.</p></dd></dl><dl><dt class="spec module" id="module-Gc"><a href="#module-Gc" class="anchor"></a><code><span class="keyword">module</span> <a href="Gc/index.html">Gc</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>General category property.</p></dd></dl><dl><dt class="spec module" id="module-Gen"><a href="#module-Gen" class="anchor"></a><code><span class="keyword">module</span> <a href="Gen/index.html">Gen</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>General properties.</p></dd></dl><dl><dt class="spec module" id="module-Hangul"><a href="#module-Hangul" class="anchor"></a><code><span class="keyword">module</span> <a href="Hangul/index.html">Hangul</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Hangul properties.</p></dd></dl><dl><dt class="spec module" id="module-Id"><a href="#module-Id" class="anchor"></a><code><span class="keyword">module</span> <a href="Id/index.html">Id</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Identifier properties.</p></dd></dl><dl><dt class="spec module" id="module-Name"><a href="#module-Name" class="anchor"></a><code><span class="keyword">module</span> <a href="Name/index.html">Name</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Name and name alias properties.</p></dd></dl><dl><dt class="spec module" id="module-Num"><a href="#module-Num" class="anchor"></a><code><span class="keyword">module</span> <a href="Num/index.html">Num</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Numeric properties.</p></dd></dl><dl><dt class="spec module" id="module-Script"><a href="#module-Script" class="anchor"></a><code><span class="keyword">module</span> <a href="Script/index.html">Script</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>Script and script extensions properties.</p></dd></dl><dl><dt class="spec module" id="module-White"><a href="#module-White" class="anchor"></a><code><span class="keyword">module</span> <a href="White/index.html">White</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></dt><dd><p>White space property.</p></dd></dl></section><section><header><h2 id="distrib_omit"><a href="#distrib_omit" class="anchor"></a>Property module distribution and omissions</h2><p>Properties are approximatively distributed in modules by scope of use like in this <a href="http://www.unicode.org/reports/tr44/#Property_Index_Table">property index table</a>. However some subset of properties live in their own modules.</p><p>Obsolete and <a href="http://www.unicode.org/reports/tr44/#Deprecated_Property_Table">deprecated</a> properties are omitted. So are those related to normalization, shaping and bidirectionality. Here is the full list of omitted properties, if you think one of these property should be added get in touch with a rationale.</p><ul><li>Case. <a href="http://www.unicode.org/reports/tr44/#Simple_Lowercase_Mapping">Simple_Lowercase_Mapping</a>, <a href="http://www.unicode.org/reports/tr44/#Simple_Uppercase_Mapping">Simple_Uppercase_Mapping</a>, <a href="http://www.unicode.org/reports/tr44/#Simple_Titlecase_Mapping">Simple_Titlecase_Mapping</a>, <a href="http://www.unicode.org/reports/tr44/#Simple_Case_Folding">Simple_Case_folding</a>, <a href="http://www.unicode.org/reports/tr44/#CWL">Changes_When_Lowercased</a>, <a href="http://www.unicode.org/reports/tr44/#CWU">Changes_When_Uppercased</a>, <a href="http://www.unicode.org/reports/tr44/#CWT">Changes_When_Titlecased</a>, <a href="http://www.unicode.org/reports/tr44/#CWCF">Changes_When_Casefolded</a>, <a href="http://www.unicode.org/reports/tr44/#CWCM">Changes_When_Casemapped</a>.</li><li>Normalization. All properties under that section name in <a href="http://www.unicode.org/reports/tr44/#Property_Index_Table">this table</a>.</li><li>Shaping and rendering. <a href="http://www.unicode.org/reports/tr44/#Joining_Group">Joining_Group</a>, <a href="http://www.unicode.org/reports/tr44/#Joining_Type">Joining_Type</a>, <a href="http://www.unicode.org/reports/tr44/#Vertical_Orientation">Vertical_Orientation</a>, <a href="http://www.unicode.org/reports/tr44/#Indic_Syllabic_Category">Indic_Syllabic_Category</a>, <a href="http://www.unicode.org/reports/tr44/#Indic_Positional_Category">Indic_Positional_Category</a>, <a href="http://www.unicode.org/reports/tr44/#Prepended_Concatenation_Mark">Prepended_Concatenation_Mark</a></li><li>Bidirectional. All properties under that section name in <a href="http://www.unicode.org/reports/tr44/#Property_Index_Table">this table</a>.</li><li>CJK. <a href="http://www.unicode.org/reports/tr44/#Unicode_Radical_Stroke">Unicode_Radical_Stroke</a>, <a href="http://www.unicode.org/reports/tr44/#Equivalent_Unified_Ideograph">Equivalent_Unified_Ideograph</a> and all the properties of the <a href="http://www.unicode.org/reports/tr38/">Unicode HAN Database</a>.</li><li>Miscellaneous. <a href="http://www.unicode.org/reports/tr44/#STerm">STerm</a>.</li><li>Contributory properties. All properties under that section in <a href="http://www.unicode.org/reports/tr44/#Property_Index_Table">this table.</a></li></ul></header></section><section><header><h2 id="uminimal"><a href="#uminimal" class="anchor"></a>Minimal Unicode introduction</h2></header><section><header><h3 id="characters"><a href="#characters" class="anchor"></a>Characters — if they exist</h3><p>The purpose of Unicode is to have a universal way of representing characters of writing systems known to the world in computer systems. Defining the notion of character is a very complicated question with both philosophical and political implications. To side step these issues, we only talk about characters from a programmer's point of view and simply say that the purpose of Unicode is to assign meaning to the integers of a well-defined integer range.</p><p>This range is called the Unicode <em>codespace</em>, it spans from <code>0x0000</code> to <code>0x10FFFF</code> and its boundaries are cast in stone. Members of this range are called Unicode <em>code points</em>. Note that an OCaml <code>int</code> value can represent them on both 32- and 64-bit platforms.</p><p>There's a lot of (non-exclusive) <a href="http://www.unicode.org/glossary/">terminology</a> predicates that can be applied to code points. I will only mention the most useful ones here.</p><p>First there are the <em>reserved</em> or <em>unassigned</em> code points, those are the integers to which the standard doesn't assign any meaning <em>yet</em>. They are reserved for future assignment and may become meaningful in newer versions of the standard. Be aware that once a code point has been assigned (aka as <em>encoded</em>) by the standard most of its properties may never change again, see the <a href="http://www.unicode.org/policies/stability_policy.html">stability policy</a> for details.</p><p>A very important subset of code points are the Unicode <em>scalar values</em>, these are the code points that belong to the ranges <code>0x0000</code>…<code>0xD7FF</code> and <code>0xE000</code>…<code>0x10FFFF</code>. This is the complete Unicode codespace minus the range <code>0xD800</code>…<code>0xDFFF</code> of so called <em>surrogate</em> code points, a hack to be able to encode all scalar values in UTF-16 (more on that below).</p><p>Scalar values are what I call, by a <b>total abuse of terminology</b>, the Unicode characters; it is what a proper <code>uchar</code> type should represent. From a programmer's point of view they are the sole integers you will have to deal with during processing and the only code points that you are allowed to serialize and deserialize to valid Unicode byte sequences. Since OCaml 4.03 the standard library defines an <span class="xref-unresolved" title="unresolved reference to &quot;Uchar.t&quot;"><code>Uchar</code>.t</span> type to represent them.</p><p>Unicode uses a standard notation to denote code points in running text. A code point is expressed as U+n where <em>n</em> is four to six uppercase hexadecimal digits with leading zeros omitted unless the code point has fewer than four digits (in <code>printf</code> words <code>&quot;U+%04X&quot;</code>). For example the code point bounds are expressed by U+0000 and U+10FFFF and the surrogate bounds by U+D800 and U+DFFF.</p></header></section><section><header><h3 id="assignements"><a href="#assignements" class="anchor"></a>Interlude — what is assigned ?</h3><p>Lots of the world's scripts are encoded in the standard. The <a href="http://www.unicode.org/charts/">code charts</a> give a precise idea of the coverage.</p><p>In order to be sucessful Unicode decided to be inclusive and to contain pre-existing international and national standards. For example the scalar values from U+0000 to U+007F correspond exactly to the code values of characters encoded by the US-ASCII standard, while those from U+0000 to U+00FF correspond exactly to the code values of ISO-8859-1 (latin1). Many other standard are injected into the codespace but their map to Unicode scalar values may not be as straightforward as the two examples given above.</p><p>One thing to be aware of is that because of the inclusive nature of the standard the same abstract character may be represented in more than one way by the standard. A simple example is the latin character &quot;é&quot;, which can either be represented by the single scalar value U+00E9 or by the <em>sequence</em> of scalar values &lt;U+0065, U+0301&gt; that is a latin small letter &quot;e&quot; followed by the combining acute accent &quot;´&quot;. This non uniqueness of representation is problematic, for example whenever you want to test sequences of scalar values for equality. Unicode solves this by defining equivalence classes between sequences of scalar values, this is called Unicode normalization and we will talk about it later.</p><p>Another issue is character spoofing. Many encoded characters ressemble each other when displayed but have different scalar values and meaning. The <a href="http://www.unicode.org/faq/security.html">Unicode Security FAQ</a> has more information and pointers about these issues.</p></header></section><section><header><h3 id="serializing"><a href="#serializing" class="anchor"></a>Serializing integers — UTF-X</h3><p>There is more than one way of representing a large integer as a sequence of bytes. The Unicode standard defines seven <em>encoding schemes</em>, also known as Unicode transformation formats (UTF), that precisely define how to encode and decode <em>scalar values</em> — take note, scalar values, <b>not code points</b> — as byte sequences.</p><ul><li>UTF-8, a scalar value is represented by a sequence of one to 4 bytes. One of the valuable property of UTF-8 is that it is compatible with the encoding of US-ASCII: the one byte sequences are solely used for encoding the 128 scalar value U+0000 to U+007F which correspond exactly to the US-ASCII code values. Any scalar value stricly greater than U+007F will use more than one byte.</li><li>UTF-16BE, a scalar value is either represented by one 16 bit big-endian integer if its scalar value fits or by two surrogate code points encoded as 16 bit big-endian integers (how exactly is beyond the scope of this introduction).</li><li>UTF-16LE is like UTF-16BE but uses little-endian encoded integers.</li><li><p>UTF-16 is either UTF-16BE or UTF-16LE. The endianness is determined by looking at the two initial bytes of the data stream:</p><ol><li>If they encode a byte order mark character (BOM, U+FEFF) they will be either <code>(0xFF,0xFE)</code>, indicating UTF-16LE, or <code>(0xFE,0xFF)</code> indicating UTF-16BE.</li><li>Otherwise UTF-16BE is assumed.</li></ol></li><li>UTF-32BE, a scalar value is represented by one 32 bit big-endian integer.</li><li>UTF-32LE is like UTF-32BE but uses little-endian encoded integers.</li><li>UTF-32 is either UTF-32BE or UTF-32LE, using the same byte order mark mechanism as UTF-16, looking at the four initial bytes of the data stream.</li></ul><p>The cost of using one representation over the other depends on the character usage. For example UTF-8 is fine for latin scripts but wasteful for east-asian scripts, while the converse is true for UTF-16. I never saw any usage of UTF-32 on disk or wires, it is very wasteful. However, in memory, UTF-32 has the advantage that characters become directly indexable.</p><p>For more information see the <a href="http://www.unicode.org/faq/utf_bom.html">Unicode UTF-8, UTF-16, UTF-32 and BOM FAQ</a>.</p></header></section><section><header><h3 id="interlude-—-useful-scalar-values"><a href="#interlude-—-useful-scalar-values" class="anchor"></a>Interlude — Useful scalar values</h3><p>The following scalar values are useful to know:</p><ul><li>U+FEFF, the byte order mark (BOM) character used to detect endiannes on byte order sensitive UTFs.</li><li>U+FFFD, the replacement character. Can be used to: stand for unrepresentable characters when transcoding from another representation, indicate that something was lost in best-effort UTF decoders, etc.</li><li>U+1F42B, the emoji bactrian camel (🐫, since Unicode 6.0.0).</li></ul></header></section><section><header><h3 id="equivalence"><a href="#equivalence" class="anchor"></a>Equivalence and normalization</h3><p>We mentioned above that concrete textual data may be represented by more than one sequence of scalar values. Latin letters with diacritics are a simple example of that. In order to be able to test two sequences of scalar values for equality we should be able to ignore these differences. The easiest way to do so is to convert them to a normal form where these differences are removed and then use binary equality to test them.</p><p>However first we need to define a notion of equality between sequences. Unicode defines two of them, which one to use depends on your processing context.</p><ul><li><em>Canonical</em> equivalence. Equivalent sequences should display and and be interpreted the same way when printed. For example the sequence &quot;B&quot;, &quot;Ä&quot; (&lt;U+0042, U+00C4&gt;) is canonically equivalent to &quot;B&quot;, &quot;A&quot;, &quot;¨&quot; (&lt;U+0042, U+0041, U+0308&gt;).</li><li><em>Compatibility</em> equivalence. Equivalent sequences may have format differences in display and may be interpreted differently in some contexts. For example the sequence made of the latin small ligature fi &quot;ﬁ&quot; (&lt;U+FB01&gt;) is compatibility equivalent to the sequence &quot;f&quot;, &quot;i&quot; (&lt;U+0066, U+0069&gt;). These two sequences are however not canonically equivalent.</li></ul><p>Canonical equivalence is included in compatiblity equivalence: two canonically equivalent sequences are also compatibility equivalent, but the converse may not be true.</p><p>A normal form is a function mapping a sequence of scalar values to a sequence of scalar values. The Unicode standard defines four different normal forms, the one to use depends on the equivalence you want and your processing context:</p><ul><li>Normalization form D (NFD). Removes any canonical difference and decomposes characters. For example the sequence &quot;é&quot; (&lt;U+00E9&gt;) will normalize to the sequence &quot;e&quot;, &quot;´&quot; (&lt;U+0065, U+0301&gt;.)</li><li>Normalization form C (NFC). Removes any canonical difference and composes characters. For example the sequence &quot;e&quot;, &quot;´&quot; (&lt;U+0065, U+0301&gt;) will normalize to the sequence &quot;é&quot; (&lt;U+00E9&gt;)</li><li>Normalization form KD (NFKD). Removes canonical and compatibility differences and decomposes characters.</li><li>Normalization form KC (NFKC). Removes canonical and compatibility differences and composes characters.</li></ul><p>Once you have two sequences in a known normal form you can compare them using binary equality. If the normal form is NFD or NFC, binary equality will entail canonical equivalence of the sequences. If the normal form is NFKC or NFKD equality will entail compatibility equivalence of the sequences. Note that normal forms are <b>not</b> closed under concatenation: if you concatenate two sequence of scalar values you have to renormalize the result.</p><p>For more information about normalization, see the <a href="http://www.unicode.org/faq/normalization.html">Normalization FAQ</a>.</p></header></section><section><header><h3 id="collation"><a href="#collation" class="anchor"></a>Collation — sorting in alphabetical order</h3><p>Normalisation forms allow to define a total order between sequences of scalar values using binary comparison. However this order is purely arbitrary. It has no meaning because the magnitude of a scalar value has, in general, no meaning. The process of ordering sequences of scalar values in a standard order like alphabetical order is called <em>collation</em>. Unicode defines a customizable algorithm to order two sequences of scalar values in a meaningful way, the Unicode collation algorithm. For more information and further pointers see the <a href="http://www.unicode.org/faq/collation.html">Unicode Collation FAQ</a>.</p></header></section></section><section><header><h2 id="tips"><a href="#tips" class="anchor"></a>Biased tips for OCaml programs and libraries</h2><ul><li><a href="index.html#uchartype"><span>Unicode characters (scalar values) as <em></em> values.</span></a></li><li><a href="index.html#utf_8_strings"><span>Unicode text as UTF-8 encoded OCaml strings</span></a></li><li><a href="index.html#utf_8_ascii"><span>UTF-8 and ASCII</span></a></li><li><a href="index.html#eqcmpnorm"><span>Equate, compare and normalize UTF-8 encoded OCaml strings</span></a></li><li><a href="index.html#boundaries"><span>Find user-perceived character, word, sentence and line boundaries in Unicode text.</span></a></li><li><a href="index.html#readline"><span>Unicode readline</span></a></li><li><a href="index.html#alphasort"><span>Sort strings alphabetically</span></a></li><li><a href="index.html#noranges"><span>Range processing</span></a></li><li><a href="index.html#transcode"><span>Transcoding</span></a></li><li><a href="index.html#ppcp"><span>Pretty-printing code points in ASCII</span></a></li><li><a href="index.html#ocamllibs"><span>Writing OCaml libraries</span></a></li></ul></header><section><header><h3 id="uchartype"><a href="#uchartype" class="anchor"></a>Unicode characters (scalar values) as <em></em> values.</h3><p>Since OCaml 4.03 the standard library defines the <span class="xref-unresolved" title="unresolved reference to &quot;Uchar.t&quot;"><code>Uchar</code>.t</span> type which represents <a href="index.html#characters"><span>Unicode scalar values</span></a>. Support for previous OCaml versions is provided by the <a href="https://github.com/ocaml/uchar"><code>uchar</code></a> OPAM/ocamlfind compatibility package.</p></header></section><section><header><h3 id="utf_8_strings"><a href="#utf_8_strings" class="anchor"></a>Unicode text as UTF-8 encoded OCaml strings</h3><p>For most OCaml programs it will be entirely sufficient to deal with Unicode by just treating the byte sequence of regular OCaml <code>string</code>s as <b>valid</b> UTF-8 encoded data.</p><p>Many libraries will already return Unicode text under this representation. Besides latin1 identifiers having been deprecated in OCaml 4.01, UTF-8 encoding your sources allows you to write UTF-8 encoded string literals directly in your programs. Be aware though that as far as OCaml's compiler is concerned these are just sequences of bytes and you can't trust these strings to be valid UTF-8 as they depend on how correctly your editor encodes them. That is you <b>will need</b> to validate and most likely normalize them unless you:</p><ul><li>Escape their valid UTF-8 bytes explicitely. For example <code>&quot;\xF0\x9F\x90\xAB&quot;</code> is the correct encoding of U+1F42B</li><li>Or use Unicode escapes (since OCaml 4.06). For example <code>&quot;\u{1F42B}&quot;</code> will UTF-8 encode the character U+1F42B in the string</li></ul><p>Checking the validity of UTF-8 strings should only be performed at the boundaries of your program: on your string literals, on data input or on the results of untrusted libraries (be careful, some libraries like Yojson will happily return invalid UTF-8 strings). This allows you to only deal with valid UTF-8 throughout your program and avoid redundant validity checks, internally or on output. The following properties of UTF-8 are useful to remember:</p><ul><li>UTF-8 validity is closed under string concatenation: concatenating two valid UTF-8 strings results in a valid UTF-8 string.</li><li>Splitting a valid UTF-8 encoded string at UTF-8 encoded US-ASCII scalar values (i.e. at any byte &lt; 128) will result in valid UTF-8 encoded substrings.</li></ul><p>For checking validity or recoding the other UTF encoding schemes into UTF-8 encoded OCaml <code>strings</code>, the <code>Uutf</code> module can be used. It will also be useful if you need to fold over the scalar values of your UTF-8 encoded strings, or build new UTF-8 strings from scalar values via <span class="xref-unresolved" title="unresolved reference to &quot;Buffer.t&quot;"><code>Buffer</code>.t</span> values. Support for the latter is however present in the OCaml <code>Buffer</code> module since OCaml 4.06.</p></header></section><section><header><h3 id="utf_8_ascii"><a href="#utf_8_ascii" class="anchor"></a>UTF-8 and ASCII</h3><p>As mentioned in <a href="index.html#serializing"><span>Serializing integers — UTF-X</span></a>, each of the 128 US-ASCII characters is represented by its own US-ASCII byte representation in UTF-8. So if you want to look for an US-ASCII character in an UTF-8 encoded string, you can just scan the bytes. But beware on the nature of your data and the algorithm you need to implement. For example to detect spaces in the string, looking for the US-ASCII space U+0020 may not be sufficient, there are a lot of other space characters like the no break space U+00A0 that are beyond the US-ASCII repertoire. Folding over the scalar values with <code>Uutf</code> and checking them with <a href="White/index.html#val-is_white_space"><code>White.is_white_space</code></a> is a better idea. Same holds for line breaks, see for example <span class="xref-unresolved" title="unresolved reference to &quot;Uutf.nln&quot;"><code>Uutf</code>.nln</span> and <span class="xref-unresolved" title="unresolved reference to &quot;Uutf.readlines&quot;"><code>Uutf</code>.readlines</span> for more information about these issues.</p></header></section><section><header><h3 id="eqcmpnorm"><a href="#eqcmpnorm" class="anchor"></a>Equate, compare and normalize UTF-8 encoded OCaml strings</h3><p>If you understood well the above section about <a href="index.html#equivalence"><span>equivalence and normalization</span></a> you should realise that blindly comparing UTF-8 encoded OCaml strings using <span class="xref-unresolved" title="unresolved reference to &quot;Pervasives.compare&quot;"><code>Pervasives</code>.compare</span> won't bring you anywhere if you don't normalize them before. The <code>Uunf</code> module can be used for that. Remember that concatenating normalized strings does <b>not</b> result in a normalized string.</p><p>Using <span class="xref-unresolved" title="unresolved reference to &quot;Pervasives.compare&quot;"><code>Pervasives</code>.compare</span> on <em>normalized</em> UTF-8 encoded OCaml strings defines a total order on them that you can use with the <code>Map</code> or <code>Set</code> modules as long as you are not interested in the actual <em>meaning</em> of the order.</p><p>For case insensitive equality have a look at the <a href="Case/index.html#caselesseq"><span>sample code</span></a> of the <a href="Case/index.html"><code>Case</code></a> module.</p></header></section><section><header><h3 id="alphasort"><a href="#alphasort" class="anchor"></a>Sort strings alphabetically</h3><p>The only solution at the moment for collating strings is to use <a href="https://github.com/yoriyuki/Camomile">Camomile</a> but be aware that it supports only Unicode 3.2 character data so don't be surprised if newer scripts don't order correctly. The official collation data also has been significantly tweaked since then.</p></header></section><section><header><h3 id="boundaries"><a href="#boundaries" class="anchor"></a>Find user-perceived character, word, sentence and line boundaries in Unicode text.</h3><p>The <code>Uuseg</code> module implements the <a href="http://www.unicode.org/reports/tr29/">Unicode text segmentation algorithms</a> to find user-perceived character, word and sentence boundaries in Unicode text. It also provides an implementation of the <a href="http://www.unicode.org/reports/tr14/">Unicode Line Breaking Algorithm</a> to find line breaks and line break opportunities.</p><p>Among other things the <code>Uuseg_string</code> module uses these algorithms to provide OCaml standard library <span class="xref-unresolved" title="unresolved reference to &quot;Format&quot;"><span>formatters</span></span> for best-effort formatting of UTF-8 encoded strings.</p></header></section><section><header><h3 id="readline"><a href="#readline" class="anchor"></a>Unicode readline</h3><p>A <code>readline</code> function as mandated by the Unicode standard is available in <span class="xref-unresolved" title="unresolved reference to &quot;Uutf.readline&quot;"><span><code>Uutf</code>'s sample code</span></span>.</p></header></section><section><header><h3 id="noranges"><a href="#noranges" class="anchor"></a>Range processing</h3><p>Forget about trying to process Unicode characters using hard coded ranges of scalar values like it was possible to do with US-ASCII. The Unicode standard is not closed, it is evolving, new characters are being assigned. This makes it impossible to derive properties based simply on their integer value or position in ranges of characters. That's the reason why we have the Unicode character database and <code>Uucp</code> to access their properties. Using <a href="White/index.html#val-is_white_space"><code>White.is_white_space</code></a> will be future proof should a new character deemed white be added to the standard (both <code>Uucp</code> and your progam will need a recompile though).</p></header></section><section><header><h3 id="transcode"><a href="#transcode" class="anchor"></a>Transcoding</h3><p>Transcoding from legacy encodings to Unicode may be quite involved, use <a href="https://github.com/yoriyuki/Camomile">Camomile</a> if you need to do that. There is however one translation that is very easy and direct: it is the one from ISO 8859-1 also known as latin1, the default encoding of OCaml <code>char</code>s. latin1 having been encoded in Unicode in the range of scalar values U+0000 to U+00FF which corresponds to latin1 code value, the translation is trivial, it is the identity:</p><pre><code class="ml">let char_to_scalar_value c = Char.code c
let char_of_scalar_value s =
    if s &gt; 255 then invalid_arg &quot;&quot; (* can't represent *) else
    Char.chr s</code></pre></header></section><section><header><h3 id="ppcp"><a href="#ppcp" class="anchor"></a>Pretty-printing code points in ASCII</h3><p><code>&quot;U+%04X&quot;</code> is an OCaml formatting string for printing an US-ASCII representation of an Unicode code point according to the standards' notational conventions. This is what the standard library <span class="xref-unresolved" title="unresolved reference to &quot;Fmt.Dump.uchar&quot;"><span class="xref-unresolved" title="unresolved reference to &quot;Fmt.Dump&quot;"><code>Fmt</code>.Dump</span>.uchar</span> formatter does for <span class="xref-unresolved" title="unresolved reference to &quot;Uchar.t&quot;"><code>Uchar</code>.t</span> values.</p></header></section><section><header><h3 id="ocamllibs"><a href="#ocamllibs" class="anchor"></a>Writing OCaml libraries</h3><p>If you write a library that deals with textual data, you should, unless technically impossible, always interact with the client of the library using Unicode. If there are other encodings involved transcode them to/from Unicode so that the client needs only to deal with Unicode, the burden of dealing with the encoding mess has to be on the library, not the client.</p><p>In this case there is no absolute need to depend on an Unicode text data structure, just use <b>valid</b> UTF-8 encoded data as OCaml <code>string</code>s and the standard library <span class="xref-unresolved" title="unresolved reference to &quot;Uchar.t&quot;"><code>Uchar</code>.t</span> type.</p><p>Specify clearly in the documentation that all the <code>string</code>s returned by or given to the library must be valid UTF-8 encoded data. This validity contract is important for performance reasons: it allows both the client and the library to trust the string and forgo redundant validity checks. Remember that concatenating valid UTF-8 strings results in valid UTF-8 string.</p></header></section></section></div></body></html>